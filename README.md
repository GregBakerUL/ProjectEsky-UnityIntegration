# ProjectEsky-UnityIntegration

Welcome to Project Esky! 

Project Esky aims to be the OpenSource, software companion to allow developing with the Deck X/North Star Display system out of the box! 
(Utilizing the Intel Realsense t265/1 or a ZED system)

This includes a unity package that handles
- Rendering (with V2 undistortion via a separate OpenGL Renderer)
- MRTK Integration with the Leap Motion controller (aligned with the user's view)
- 6DoF Head Tracking + Re-Localization events (Save map, load map, add persistence, callbacks, ect.)
- Spatial mapping (Via the ZED SDK, with future plans to rip out the point cloud for t265 to allow scene authoring/phantom model interactions)
- Object Persistence (Via the t265/1 or ZED SDK <Available in another repo, TBA>)

Required Software:
- Unity 2019.4.X
- LeapMotion libraries (I recommend the latest orion beta)
- Visual Studio C++ Redistributable: https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads
- Microsoft Direct X End-User Redistributable: https://www.microsoft.com/en-gb/download/confirmation.aspx?id=35
- Windows (Sadly, for now.....)


Currently, the v2 + leapmotion + T265 calibration in this project has been pre calibrated and setup, 
It utilizes a DeckX variation of the Project North-Star display, purchasable here: https://www.smart-prototyping.com/AR-VR-MR-XR 
Your headset, provided there is little warping in the 3D print/sensor arrangement, should be good to go from here!

If you want to improve the visual quality, calibrate your NS using the v2 method described here: https://project-north-star.gitbook.io/project-north-star/calibration/calibration-v2

Copy/Paste the 4 float arrays generated by the northstar v2 calibration, into /DisplayCalibration.json
(Warning, DO NOT JUST COPY AND PASTE THE FILE, or you'll need to re-add the extra variables I set, at least until the calibration method includes these variables in the JSON file)

You can perform 6DOF and LeapMotion hand calibration here: https://github.com/HyperLethalVector/ProjectEsky-6DOF-HandAligner-Interactive 

Load up the project in unity, load /Assets/HandInteractionExamples.unity

Adjust the DisplaySettings.json file with the window position x/y, and resolution of your render textures
if your image isn't clear, try toggling the 'requires rotation' boolean (to rotate the cameras 90 degrees)
with any luck you, when you hit play, you should see an undistorted stereo pair on your headset.

You can now adjust the offset for the left and right eye, using the DisplaySettings.json file, 
you should try your best to adjust the offsets so that the objects in the scene overlap perfectly!

For hand-aligning the leapmotion controller, you can use the tool in Assets/Scenes/LMCalibration.unity

<TODO: Add instructions for relocalization>
<TODO: Integrate stabilizer, it's working but buggy due to tracker jitter>

KNOWN ISSUES:
- The relocalizer is known to be a bit finnicky, try reloading the map onto the t265
- With unity 2020, the editor might get 

If you wish to ask questions, please join the North Star Community on Discord! 
https://discord.gg/fPza2G


Quick FAQ:

1) Hey, I see some extra glsl shaders in the root directory, what are these for?
Actually these are what powers the magic behind the V2 renderer system, I am passing a render texture pointer to a separate OpenGL instance! Allowing for realtime updates and undistortion! (And is what will allow the stabilization techniques later, stay tuned ;) )

2) Wait, does that mean I can use _any_ headset?
YOU ARE GOSH DARN RIGHT!
By editing the vertex and fragment shaders, (or heck, even the DirectX instance!) you can use _any_ headset.
Alternatively you could replace the cameras in the unity scene with any renderer, steamVR, ect. and still utilize the leapmotion MRTK integration esky provides!

THIS CODE IS LICENSED UNDER THE 3 CLAUSE BSD LICENSE.

While I don't really care where and how you use this software, with great power comes great responsibility.
That being said, using this software comes with one condition, that you please cite the following paper:
<Bibtex yet to be added, paper is waiting to release>
<https://www.researchgate.net/publication/344337571_Project_Esky_Enabling_High_Fidelity_Augmented_Reality_Content_on_an_Open_Source_Platform>

If you're looking to contribute, feel free to fork! 

Finally, I always welcome requests for help/collaborations, especially if you're building fun shit! Seek me out :D 
